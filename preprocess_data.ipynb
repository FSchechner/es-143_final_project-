{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Frame Extraction Preprocessing\n",
    "\n",
    "This notebook extracts frames from source videos and saves them for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "VIDEO_PATH = 'source_videos/bunny.MOV'\n",
    "OUTPUT_DIR = 'data/bunny'\n",
    "FRAME_RATE = 1  # Extract 1 frame per second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_frames(video_path, output_dir, fps=1):\n",
    "    \"\"\"\n",
    "    Extract frames from a video at specified frame rate.\n",
    "    \n",
    "    Args:\n",
    "        video_path: Path to the input video file\n",
    "        output_dir: Directory to save extracted frames\n",
    "        fps: Number of frames to extract per second (default: 1)\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    Path(output_dir).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Open the video file\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    \n",
    "    if not cap.isOpened():\n",
    "        print(f\"Error: Could not open video file {video_path}\")\n",
    "        return\n",
    "    \n",
    "    # Get video properties\n",
    "    video_fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    duration = total_frames / video_fps\n",
    "    \n",
    "    print(f\"Video FPS: {video_fps}\")\n",
    "    print(f\"Total frames: {total_frames}\")\n",
    "    print(f\"Duration: {duration:.2f} seconds\")\n",
    "    print(f\"Extracting {fps} frame(s) per second...\\n\")\n",
    "    \n",
    "    # Calculate frame interval\n",
    "    frame_interval = int(video_fps / fps)\n",
    "    \n",
    "    frame_count = 0\n",
    "    saved_count = 0\n",
    "    \n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        \n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        # Save frame at specified interval\n",
    "        if frame_count % frame_interval == 0:\n",
    "            frame_filename = os.path.join(output_dir, f'frame_{saved_count:04d}.jpg')\n",
    "            cv2.imwrite(frame_filename, frame)\n",
    "            saved_count += 1\n",
    "            \n",
    "            if saved_count % 10 == 0:\n",
    "                print(f\"Saved {saved_count} frames...\")\n",
    "        \n",
    "        frame_count += 1\n",
    "    \n",
    "    cap.release()\n",
    "    \n",
    "    print(f\"\\nExtraction complete!\")\n",
    "    print(f\"Total frames saved: {saved_count}\")\n",
    "    print(f\"Frames saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video FPS: 23.997253533215083\n",
      "Total frames: 699\n",
      "Duration: 29.13 seconds\n",
      "Extracting 1 frame(s) per second...\n",
      "\n",
      "Saved 10 frames...\n",
      "Saved 20 frames...\n",
      "Saved 30 frames...\n",
      "\n",
      "Extraction complete!\n",
      "Total frames saved: 31\n",
      "Frames saved to: data/bunny\n"
     ]
    }
   ],
   "source": [
    "# Extract frames from bunny.MOV\n",
    "extract_frames(VIDEO_PATH, OUTPUT_DIR, FRAME_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of frames extracted: 31\n",
      "First few frames: ['frame_0000.jpg', 'frame_0001.jpg', 'frame_0002.jpg', 'frame_0003.jpg', 'frame_0004.jpg']\n",
      "Last few frames: ['frame_0026.jpg', 'frame_0027.jpg', 'frame_0028.jpg', 'frame_0029.jpg', 'frame_0030.jpg']\n"
     ]
    }
   ],
   "source": [
    "# Verify the extracted frames\n",
    "frames = sorted(os.listdir(OUTPUT_DIR))\n",
    "print(f\"Number of frames extracted: {len(frames)}\")\n",
    "print(f\"First few frames: {frames[:5]}\")\n",
    "print(f\"Last few frames: {frames[-5:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quality Check: Brightness and Saturation Analysis\n",
    "\n",
    "For photometric stereo, we need to check:\n",
    "1. **Saturation** - Overexposed pixels (255 value) lose surface information\n",
    "2. **Dynamic range** - Need detail in both highlights and shadows\n",
    "3. **Consistent exposure** - All images should have similar brightness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_brightness_saturation(image_dir, sample_size=5):\n",
    "    \"\"\"\n",
    "    Analyze brightness and saturation levels in extracted frames.\n",
    "    \n",
    "    Args:\n",
    "        image_dir: Directory containing extracted frames\n",
    "        sample_size: Number of sample images to analyze\n",
    "    \"\"\"\n",
    "    frames = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])\n",
    "    \n",
    "    if len(frames) == 0:\n",
    "        print(\"No frames found!\")\n",
    "        return\n",
    "    \n",
    "    # Sample evenly distributed frames\n",
    "    step = max(1, len(frames) // sample_size)\n",
    "    sample_frames = frames[::step][:sample_size]\n",
    "    \n",
    "    print(f\"Analyzing {len(sample_frames)} sample frames...\\n\")\n",
    "    \n",
    "    saturation_percentages = []\n",
    "    mean_intensities = []\n",
    "    \n",
    "    for frame_name in sample_frames:\n",
    "        img_path = os.path.join(image_dir, frame_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        \n",
    "        if img is None:\n",
    "            continue\n",
    "            \n",
    "        # Convert to grayscale for analysis\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Check saturation (pixels at 255)\n",
    "        saturated_pixels = np.sum(gray >= 254)\n",
    "        total_pixels = gray.size\n",
    "        saturation_pct = (saturated_pixels / total_pixels) * 100\n",
    "        \n",
    "        # Mean intensity\n",
    "        mean_intensity = np.mean(gray)\n",
    "        \n",
    "        saturation_percentages.append(saturation_pct)\n",
    "        mean_intensities.append(mean_intensity)\n",
    "        \n",
    "        print(f\"{frame_name}:\")\n",
    "        print(f\"  Mean intensity: {mean_intensity:.1f}/255\")\n",
    "        print(f\"  Saturated pixels: {saturation_pct:.2f}%\")\n",
    "        \n",
    "        # Warning if too much saturation\n",
    "        if saturation_pct > 5:\n",
    "            print(f\"  ⚠️  WARNING: High saturation! May lose surface detail\")\n",
    "        print()\n",
    "    \n",
    "    # Overall statistics\n",
    "    print(\"=\" * 50)\n",
    "    print(\"OVERALL STATISTICS:\")\n",
    "    print(f\"Average mean intensity: {np.mean(mean_intensities):.1f}/255\")\n",
    "    print(f\"Average saturation: {np.mean(saturation_percentages):.2f}%\")\n",
    "    print(f\"Intensity std dev: {np.std(mean_intensities):.1f}\")\n",
    "    \n",
    "    if np.mean(saturation_percentages) > 5:\n",
    "        print(\"\\n⚠️  HIGH SATURATION DETECTED!\")\n",
    "        print(\"Consider reducing exposure or using HDR techniques\")\n",
    "    \n",
    "    if np.std(mean_intensities) > 20:\n",
    "        print(\"\\n⚠️  INCONSISTENT EXPOSURE!\")\n",
    "        print(\"Images have varying brightness - may need normalization\")\n",
    "    \n",
    "    return saturation_percentages, mean_intensities\n",
    "\n",
    "# Run analysis\n",
    "sat_pct, mean_int = analyze_brightness_saturation(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Sample Frames\n",
    "\n",
    "Check that frames show different lighting directions and all elements are visible:\n",
    "- Light probe (sphere)\n",
    "- White balance sheet\n",
    "- Bunny (object of interest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_sample_frames(image_dir, num_samples=6):\n",
    "    \"\"\"Display sample frames to verify lighting variation.\"\"\"\n",
    "    frames = sorted([f for f in os.listdir(image_dir) if f.endswith(('.jpg', '.png'))])\n",
    "    \n",
    "    step = max(1, len(frames) // num_samples)\n",
    "    sample_frames = frames[::step][:num_samples]\n",
    "    \n",
    "    fig, axes = plt.subplots(2, 3, figsize=(15, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, frame_name in enumerate(sample_frames):\n",
    "        img_path = os.path.join(image_dir, frame_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img_rgb = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        axes[idx].imshow(img_rgb)\n",
    "        axes[idx].set_title(f'{frame_name}')\n",
    "        axes[idx].axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"Displayed {len(sample_frames)} sample frames\")\n",
    "    print(\"✓ Verify that lighting direction changes across frames\")\n",
    "    print(\"✓ Check that light probe, white balance sheet, and bunny are visible\")\n",
    "\n",
    "visualize_sample_frames(OUTPUT_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next Steps for Photometric Stereo Pipeline\n",
    "\n",
    "Based on your setup, you'll need to create:\n",
    "\n",
    "### 1. **Masks** (3 separate masks):\n",
    "   - **Bunny mask** - Isolate the object of interest\n",
    "   - **Light probe mask** - Identify the sphere for light direction calibration\n",
    "   - **White balance mask** - Mark the white balance sheet for normalization\n",
    "\n",
    "### 2. **Light Direction Calibration**:\n",
    "   - Use Hough circle detection on the light probe\n",
    "   - Find brightest point on sphere for each frame\n",
    "   - Calculate 3D light direction vector\n",
    "\n",
    "### 3. **Intensity Normalization**:\n",
    "   - Use white balance sheet to normalize brightness across frames\n",
    "   - Compensates for varying light intensities\n",
    "\n",
    "### 4. **Shadow Detection** (optional but recommended):\n",
    "   - Identify cast shadows that violate Lambertian assumptions\n",
    "   - Exclude shadowed pixels from reconstruction\n",
    "\n",
    "### Key Assumptions for Photometric Stereo:\n",
    "- ✓ **Fixed camera** - Object doesn't move between frames\n",
    "- ✓ **Lambertian surface** - Diffuse reflection (works well for stuffed animals)\n",
    "- ✓ **Distant point lights** - Light direction is consistent across object\n",
    "- ✓ **Different light directions** - Need at least 3, more is better (20+ ideal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
